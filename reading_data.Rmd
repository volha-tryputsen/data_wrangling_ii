---
title: "Reading Data"
author: "Volha Tryputsen"
date: "October 23 - 25, 2017"
output: 
  html_document:
    theme: cosmo
    highlight: haddock
    toc: true
    toc_float:
      collapse: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rvest) # for scraping
library(httr) # for http requests
```

# Scraping  

* Find website  
* choose html nodes using appropriate css 
* convert html to desired output format: table, text etc.


## Extracting tables   
Steps:
1. get html data
2. choose your css
3. convert html using the css

### example 1 - NSDUH 

1. get html with **read_html()**
```{r example1_step1}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_xml = read_html(url)
```

2. what css tag(css selector) I need, using **html_nodes(css =...)**
```{r example1_step2}
# choose css "table" tag
# html_nodes() extracts html nodes based on the css features, tables in this specific case
drug_use_xml %>%
  html_nodes(css = "table")
```
We have a list of 15 tables.  
Exract only a table you are interested in. I will exttrat 1st table:  

3. use **html_table()** to convert css-defined html table into tibble:  
```{r example1_step3}
  (drug_use_xml %>% html_nodes(css = "table"))[[1]] %>%
  html_table() %>%
  names()

# need to delete the note at the beginning of each column
table_marj = 
  (drug_use_xml %>% html_nodes(css = "table"))[[1]] %>%
  html_table() %>%
  # . means take current data frame 
  # and take out the 1st row
  .[-1,] %>% 
  #View()
  as_tibble()
```

Now I have exactly the table I want! Needs cleaning though.  



### example 2 - NYC Cost of living   

I'd like to understand the impact of my life choices by looking at cost of living in NYC compared to the rest of the US. The table below should help!

**url %>% read_html() %>% html_nodes(css = "table") %>% html_table()**
** extract html %>% get the nodes with css selector %>% turn them into output(table, text..)**
```{r example2}
url = "https://www.bestplaces.net/cost_of_living/city/new_york/new_york"
nyc_cost_xml = read_html(url)
nyc_cost_table = 
  (nyc_cost_xml %>% html_nodes(css = "table"))[[2]] %>%
  html_table(header = TRUE)
```



## CSS selectors
Different kinds of css selectors

### example 1 - harry poter cast names  
**extract text**

```{r}
url = "http://www.imdb.com/title/tt0241527/"
hpss_xml = read_html(url)

hpss_cast = hpss_xml %>%
  html_nodes(css = ".itemprop .itemprop") %>% 
  html_text()
```


### example 2 - toothbrushe review from amazon  
**exract reviews titles**

Dental [hygiene](https://www.google.com/search?&rls=en&q=hygiene&ie=UTF-8&oe=UTF-8).

```{r}
url = "https://www.amazon.com/Philips-Sonicare-rechargeable-toothbrush-HX6211/product-reviews/B00YAR7ZFM/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&reviewerType=all_reviews&sortBy=recent&pageNumber=2"

toothbrush_xml = read_html(url)

# .a-color-base css tag in unstable in terms of interaction with amazon
toothbrush_titles = toothbrush_xml %>%
  html_nodes(css = "#cm_cr-review_list .a-color-base") %>% 
  html_text()
#instead of .a-color-base, use .review-title, because it is more stable
toothbrush_titles = toothbrush_xml %>%
  html_nodes(css = "#cm_cr-review_list .review-title") %>% 
  html_text()

toothbrush_stars = toothbrush_xml %>%
  html_nodes(css = "#cm_cr-review_list .review-rating") %>% 
  html_text()

toothbrush_df = data_frame(
  title = toothbrush_titles,
  stars = toothbrush_stars
)
```



# APIs 
accessing data via web-API - a front-end software which makes a request to a server.  

## example 1 - NYC water consumption  
NYC open data project.  

* Getting water data via the API. 
```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/waf7-5gvc.csv") %>%
  content("parsed")
```

* Getting the same data using JSON (when data doesnt fit into a nice rectangular shape)  
```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/waf7-5gvc.json") %>% 
  content("text") %>%
  jsonlite::fromJSON() %>%
  as_tibble()
```

## example 2 - BRFSS

```{r}
brfss = 
  GET("https://chronicdata.cdc.gov/api/views/hn4x-zwk7/rows.csv?accessType=DOWNLOAD") %>% 
  content("parsed")
#View(brfss)
```


## example 3 - catch the pokemon  

```{r}
poke = 
  GET("http://pokeapi.co/api/v2/pokemon/1") %>% # extract the data
  content() # get the content

names(poke)
class(poke$forms) # list
class(poke$name) # character
```
